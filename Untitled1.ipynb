{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e5689-9249-4514-aba5-991516ad6244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import aux_funcs  as af\n",
    "import network_architectures as arcs\n",
    "import model_funcs as mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea39147d-2609-44fd-a9db-32727663b9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlockWOutput(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, channels, params, stride=1):\n",
    "        super(BasicBlockWOutput, self).__init__()\n",
    "        add_output = params[0]\n",
    "        num_classes = params[1]\n",
    "        input_size = params[2]\n",
    "        self.output_id = params[3]\n",
    "\n",
    "        self.depth = 2\n",
    "\n",
    "        layers = nn.ModuleList()\n",
    "\n",
    "        conv_layer = []\n",
    "        conv_layer.append(nn.Conv2d(in_channels, channels, kernel_size=3, stride=stride, padding=1, bias=False))\n",
    "        conv_layer.append(nn.BatchNorm2d(channels))\n",
    "        conv_layer.append(nn.ReLU())\n",
    "        conv_layer.append(nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "        conv_layer.append(nn.BatchNorm2d(channels))\n",
    "\n",
    "        layers.append(nn.Sequential(*conv_layer))\n",
    "\n",
    "        shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != self.expansion*channels:\n",
    "            shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion*channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*channels)\n",
    "            )\n",
    "\n",
    "        layers.append(shortcut)\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        self.layers = layers\n",
    "\n",
    "        if add_output:\n",
    "            self.output = af.InternalClassifier(input_size, self.expansion*channels, num_classes)\n",
    "            self.no_output = False\n",
    "\n",
    "        else:\n",
    "            self.output = None\n",
    "            self.forward = self.only_forward\n",
    "            self.no_output = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        fwd = self.layers[0](x) # conv layers\n",
    "        fwd = fwd + self.layers[1](x) # shortcut\n",
    "        return self.layers[2](fwd), 1, self.output(fwd)         # output layers for this module\n",
    "\n",
    "    def only_output(self, x):\n",
    "        fwd = self.layers[0](x) # conv layers\n",
    "        fwd = fwd + self.layers[1](x) # shortcut\n",
    "        fwd = self.layers[2](fwd) # activation\n",
    "        out = self.output(fwd)         # output layers for this module\n",
    "        return out\n",
    "\n",
    "    def only_forward(self, x):\n",
    "        fwd = self.layers[0](x) # conv layers\n",
    "        fwd = fwd + self.layers[1](x) # shortcut\n",
    "        return self.layers[2](fwd), 0, None # activation\n",
    "\n",
    "class ResNet_SDN(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(ResNet_SDN, self).__init__()\n",
    "        self.num_blocks = params['num_blocks']\n",
    "        self.num_classes = int(params['num_classes'])\n",
    "        self.augment_training = params['augment_training']\n",
    "        self.input_size = int(params['input_size'])\n",
    "        self.block_type = params['block_type']\n",
    "        self.add_out_nonflat = params['add_ic']\n",
    "        self.add_output = [item for sublist in self.add_out_nonflat for item in sublist]\n",
    "        self.init_weights = params['init_weights']\n",
    "        self.train_func = mf.sdn_train\n",
    "        self.in_channels = 16\n",
    "        self.num_output = sum(self.add_output) + 1\n",
    "        self.test_func = mf.sdn_test\n",
    "\n",
    "        self.init_depth = 1\n",
    "        self.end_depth = 1\n",
    "        self.cur_output_id = 0\n",
    "\n",
    "        self.stop_ic_id = -1\n",
    "\n",
    "        self.init_rpf_channels = params['init_rpf_pannel']\n",
    "        self.use_rpf = params['use_rpf']\n",
    "\n",
    "        if self.block_type == 'basic':\n",
    "            self.block = BasicBlockWOutput\n",
    "\n",
    "        init_conv = []\n",
    "\n",
    "        if self.input_size ==  32: # cifar10\n",
    "            self.cur_input_size = self.input_size\n",
    "            if self.use_rpf:\n",
    "                init_conv.append(nn.Conv2d(3, self.in_channels - self.init_rpf_channels, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "                init_conv.append(nn.Conv2d(3, self.init_rpf_channels, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "            else:\n",
    "                init_conv.append(nn.Conv2d(3, self.in_channels, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "        else: # tiny imagenet\n",
    "            self.cur_input_size = int(self.input_size/2)\n",
    "            if self.use_rpf:\n",
    "                init_conv.append(nn.Conv2d(3, self.in_channels - self.init_rpf_channels, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "                init_conv.append(nn.Conv2d(3, self.init_rpf_channels, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "            else:\n",
    "                init_conv.append(nn.Conv2d(3, self.in_channels, kernel_size=3, stride=2, padding=1, bias=False))\n",
    "\n",
    "        init_conv.append(nn.BatchNorm2d(self.in_channels))\n",
    "        init_conv.append(nn.ReLU())\n",
    "\n",
    "        self.init_conv = nn.Sequential(*init_conv)\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.extend(self._make_layer(self.in_channels, block_id=0, stride=1))\n",
    "\n",
    "        self.cur_input_size = int(self.cur_input_size/2)\n",
    "        self.layers.extend(self._make_layer(32, block_id=1, stride=2))\n",
    "\n",
    "        self.cur_input_size = int(self.cur_input_size/2)\n",
    "        self.layers.extend(self._make_layer(64, block_id=2, stride=2))\n",
    "\n",
    "        end_layers = []\n",
    "\n",
    "        end_layers.append(nn.AvgPool2d(kernel_size=8))\n",
    "        end_layers.append(af.Flatten())\n",
    "        end_layers.append(nn.Linear(64*self.block.expansion, self.num_classes))\n",
    "        self.end_layers = nn.Sequential(*end_layers)\n",
    "\n",
    "        if self.init_weights:\n",
    "            self.initialize_weights()\n",
    "\n",
    "    def _make_layer(self, channels, block_id, stride):\n",
    "        num_blocks = int(self.num_blocks[block_id])\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for cur_block_id, stride in enumerate(strides):\n",
    "            add_output = self.add_out_nonflat[block_id][cur_block_id]\n",
    "            params  = (add_output, self.num_classes, int(self.cur_input_size), self.cur_output_id)\n",
    "            layers.append(self.block(self.in_channels, channels, params, stride))\n",
    "            self.in_channels = channels * self.block.expansion\n",
    "            self.cur_output_id += add_output\n",
    "\n",
    "        return layers\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def random_rp_matrix(self):\n",
    "        param = next(self.init_conv[0].parameters())\n",
    "        kernel_size = param.data.size()[-1]\n",
    "        param.data = torch.normal(mean=0.0, std=1/kernel_size, size=param.data.size()).to('cuda')\n",
    "\n",
    "    def rp_forward(self, x, out, kernel):\n",
    "        rp_out = kernel(x)\n",
    "        if out is None:\n",
    "            return rp_out\n",
    "        else:\n",
    "            out = torch.cat([out, rp_out], dim=1)\n",
    "            return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        if self.use_rpf:\n",
    "            fwd = self.init_conv[0](x)\n",
    "            fwd = self.rp_forward(x, fwd, self.init_conv[1])\n",
    "            fwd = self.init_conv[2](fwd)\n",
    "        else:\n",
    "            fwd = self.init_conv(x)\n",
    "        for layer in self.layers:\n",
    "            fwd, is_output, output = layer(fwd)\n",
    "            if is_output:\n",
    "                if len(outputs) == self.stop_ic_id:\n",
    "                    return output\n",
    "                outputs.append(output)\n",
    "        fwd = self.end_layers(fwd)\n",
    "        outputs.append(fwd)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    # takes a single input\n",
    "    def early_exit(self, x):\n",
    "        confidences = []\n",
    "        outputs = []\n",
    "\n",
    "        fwd = self.init_conv(x)\n",
    "        output_id = 0\n",
    "        for layer in self.layers:\n",
    "            fwd, is_output, output = layer(fwd)\n",
    "\n",
    "            if is_output:\n",
    "                outputs.append(output)\n",
    "                softmax = nn.functional.softmax(output[0], dim=0)\n",
    "\n",
    "                confidence = torch.max(softmax)\n",
    "                confidences.append(confidence)\n",
    "\n",
    "                if confidence >= self.confidence_threshold:\n",
    "                    is_early = True\n",
    "                    return output, output_id, is_early\n",
    "\n",
    "                output_id += is_output\n",
    "\n",
    "        output = self.end_layers(fwd)\n",
    "        outputs.append(output)\n",
    "\n",
    "        softmax = nn.functional.softmax(output[0], dim=0)\n",
    "        confidence = torch.max(softmax)\n",
    "        confidences.append(confidence)\n",
    "        max_confidence_output = np.argmax(confidences)\n",
    "        is_early = False\n",
    "        return outputs[max_confidence_output], max_confidence_output, is_early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47fdf893-9e34-4b3c-b0b1-03d6c2b1ae3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'init_rpf_pannel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m model_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mic_only\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmilestones\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m15\u001b[39m]\n\u001b[1;32m     25\u001b[0m model_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mic_only\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgammas\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.1\u001b[39m]\n\u001b[0;32m---> 26\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mResNet_SDN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [15], line 85\u001b[0m, in \u001b[0;36mResNet_SDN.__init__\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcur_output_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_ic_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_rpf_channels \u001b[38;5;241m=\u001b[39m \u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minit_rpf_pannel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_rpf \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_rpf\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbasic\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'init_rpf_pannel'"
     ]
    }
   ],
   "source": [
    "model_params = {}\n",
    "model_params['task'] = 'cifar10'\n",
    "model_params['input_size'] = 32\n",
    "model_params['num_classes'] = 10\n",
    "model_params['block_type'] = 'basic'\n",
    "model_params['num_blocks'] = [9,9,9]\n",
    "model_params['add_ic'] = [[0, 0, 0, 1, 0, 0, 0, 1, 0], [0, 0, 1, 0, 0, 0, 1, 0, 0], [0, 1, 0, 0, 0, 1, 0, 0, 0]] # 15, 30, 45, 60, 75, 90 percent of GFLOPs\n",
    "model_params['network_type'] = 'resnet56'\n",
    "model_params['augment_training'] = True\n",
    "model_params['init_weights'] = True\n",
    "model_params['architecture'] = 'sdn'\n",
    "model_params['base_model'] = 'resnet56'\n",
    "network_type = model_params['network_type']\n",
    "model_params['momentum'] = 0.9\n",
    "model_params['learning_rate'] = 0.1\n",
    "model_params['epochs'] = 100\n",
    "model_params['milestones'] = [35, 60, 85]\n",
    "model_params['gammas'] = [0.1, 0.1, 0.1]\n",
    "\n",
    "# SDN ic_only training params\n",
    "model_params['ic_only'] = {}\n",
    "model_params['ic_only']['learning_rate'] = 0.001 # lr for full network training after sdn modification\n",
    "model_params['ic_only']['epochs'] = 25\n",
    "model_params['ic_only']['milestones'] = [15]\n",
    "model_params['ic_only']['gammas'] = [0.1]\n",
    "model = ResNet_SDN(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5c265f1-f0a2-413f-9119-0ea69c1067ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.stop_ic_id = 1\n",
    "batch_shape = [128, 3, 32, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef35e95-cfba-44fe-b87c-4e864d641cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f942c3d-4ea3-477c-a100-5c748ef280b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_attack(model,layer_id, test_loader, atk, atk_name):\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    n = 0\n",
    "    model.eval()\n",
    "    model.stop_ic_id = layer_id\n",
    "    for i, (X, y) in enumerate(test_loader):\n",
    "        X, y = X.to('cuda'), y.to('cuda')\n",
    "\n",
    "        #if args.rp:\n",
    "            # random select a path to attack\n",
    "        #    model.module.random_rp_matrix()\n",
    "\n",
    "        X_adv = atk(X, y)  # advtorch\n",
    "\n",
    "        #if args.rp:\n",
    "         #   # random select a path to infer\n",
    "          #  model.module.random_rp_matrix()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(X_adv)\n",
    "        loss = F.cross_entropy(output, y)\n",
    "        test_loss += loss.item() * y.size(0)\n",
    "        test_acc += (output.max(1)[1] == y).sum().item()\n",
    "        n += y.size(0)\n",
    "\n",
    "    pgd_acc = test_acc / n\n",
    "    print('Attack_type: [{:s}] done, acc: {:.4f} \\t'.format(atk_name, pgd_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14037d1b-37af-45e8-b69f-43d976f1b4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.0568, -3.5276,  8.4635,  ...,  0.9191, -2.0948,  5.1047],\n",
       "         [-0.2937, -2.9282,  7.2088,  ...,  0.4159, -2.3300,  5.0619],\n",
       "         [-1.0225, -3.4461,  7.7779,  ..., -0.2592, -1.9531,  4.8934],\n",
       "         ...,\n",
       "         [-0.3686, -3.8420,  7.8554,  ...,  0.3382, -1.8080,  5.1317],\n",
       "         [-0.9766, -3.8278,  7.7708,  ...,  0.2753, -2.6839,  5.1647],\n",
       "         [-0.8822, -3.5565,  8.2377,  ...,  0.3630, -2.7631,  4.6707]],\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " 0,\n",
       " True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = torch.rand(batch_shape)\n",
    "model.confidence_threshold = 0.5\n",
    "model.early_exit(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae36a0-3e93-435b-a2ee-6646064e333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar = af.get_dataset(\"cifar10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63edf0-a3a0-4ef8-8cb2-c51aed5a315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchattacks\n",
    "atk = torchattacks.FGSM(model, eps=8/255)\n",
    "atk.set_normalization_used(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "evaluate_attack(model,1, cifar.test_loader, atk, 'fgsm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787c3a03-4094-4ae1-a5ce-e8429b897b0c",
   "metadata": {},
   "source": [
    "python train_imagenet.py --pretrained --lr 0.02 --lr_schedule cosine --batch_size 1024 --epochs 90 --adv_train --rp --rp_block -1 -1 --rp_out_channel 48 --rp_weight_decay 1e-2 --save_dir resnet50_imagenet_RPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "82db9285-7f24-4b78-b240-4800da278bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlockWOutput(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, channels, params, stride=1):\n",
    "        super(BasicBlockWOutput, self).__init__()\n",
    "        add_output = params[0]\n",
    "        num_classes = params[1]\n",
    "        input_size = params[2]\n",
    "        self.output_id = params[3]\n",
    "\n",
    "        self.depth = 2\n",
    "\n",
    "        layers = nn.ModuleList()\n",
    "\n",
    "        conv_layer = []\n",
    "        conv_layer.append(nn.Conv2d(in_channels, channels, kernel_size=3, stride=stride, padding=1, bias=False))\n",
    "        conv_layer.append(nn.BatchNorm2d(channels))\n",
    "        conv_layer.append(nn.ReLU())\n",
    "        conv_layer.append(nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "        conv_layer.append(nn.BatchNorm2d(channels))\n",
    "\n",
    "        layers.append(nn.Sequential(*conv_layer))\n",
    "\n",
    "        shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != self.expansion*channels:\n",
    "            shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion*channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*channels)\n",
    "            )\n",
    "\n",
    "        layers.append(shortcut)\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        self.layers = layers\n",
    "\n",
    "        if add_output:\n",
    "            self.output = af.InternalClassifier(input_size, self.expansion*channels, num_classes)\n",
    "            self.no_output = False\n",
    "\n",
    "        else:\n",
    "            self.output = None\n",
    "            self.forward = self.only_forward\n",
    "            self.no_output = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        fwd = self.layers[0](x) # conv layers\n",
    "        fwd = fwd + self.layers[1](x) # shortcut\n",
    "        return self.layers[2](fwd), 1, self.output(fwd)         # output layers for this module\n",
    "\n",
    "    def only_output(self, x):\n",
    "        fwd = self.layers[0](x) # conv layers\n",
    "        fwd = fwd + self.layers[1](x) # shortcut\n",
    "        fwd = self.layers[2](fwd) # activation\n",
    "        out = self.output(fwd)         # output layers for this module\n",
    "        return out\n",
    "\n",
    "    def only_forward(self, x):\n",
    "        fwd = self.layers[0](x) # conv layers\n",
    "        fwd = fwd + self.layers[1](x) # shortcut\n",
    "        return self.layers[2](fwd), 0, None # activation\n",
    "\n",
    "class ResNet_SDN(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(ResNet_SDN, self).__init__()\n",
    "        self.num_blocks = params['num_blocks']\n",
    "        self.num_classes = int(params['num_classes'])\n",
    "        self.augment_training = params['augment_training']\n",
    "        self.input_size = int(params['input_size'])\n",
    "        self.block_type = params['block_type']\n",
    "        self.add_out_nonflat = params['add_ic']\n",
    "        self.add_output = [item for sublist in self.add_out_nonflat for item in sublist]\n",
    "        self.init_weights = params['init_weights']\n",
    "        self.train_func = mf.sdn_train\n",
    "        self.in_channels = 16\n",
    "        self.num_output = sum(self.add_output) + 1\n",
    "        self.test_func = mf.sdn_test\n",
    "\n",
    "        self.init_depth = 1\n",
    "        self.end_depth = 1\n",
    "        self.cur_output_id = 0\n",
    "\n",
    "        self.stop_ic_id = -1\n",
    "\n",
    "        self.init_rpf_channels = params['init_rpf_pannel']\n",
    "        self.use_rpf = params['use_rpf']\n",
    "\n",
    "        if self.block_type == 'basic':\n",
    "            self.block = BasicBlockWOutput\n",
    "\n",
    "        init_conv = []\n",
    "\n",
    "        if self.input_size ==  32: # cifar10\n",
    "            self.cur_input_size = self.input_size\n",
    "            if self.use_rpf:\n",
    "                init_conv.append(nn.Conv2d(3, self.in_channels - self.init_rpf_channels, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "                init_conv.append(nn.Conv2d(3, self.init_rpf_channels, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "            else:\n",
    "                init_conv.append(nn.Conv2d(3, self.in_channels, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "        else: # tiny imagenet\n",
    "            self.cur_input_size = int(self.input_size/2)\n",
    "            if self.use_rpf:\n",
    "                init_conv.append(nn.Conv2d(3, self.in_channels - self.init_rpf_channels, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "                init_conv.append(nn.Conv2d(3, self.init_rpf_channels, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "            else:\n",
    "                init_conv.append(nn.Conv2d(3, self.in_channels, kernel_size=3, stride=2, padding=1, bias=False))\n",
    "\n",
    "        init_conv.append(nn.BatchNorm2d(self.in_channels))\n",
    "        init_conv.append(nn.ReLU())\n",
    "\n",
    "        self.init_conv = nn.Sequential(*init_conv)\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.extend(self._make_layer(self.in_channels, block_id=0, stride=1))\n",
    "\n",
    "        self.cur_input_size = int(self.cur_input_size/2)\n",
    "        self.layers.extend(self._make_layer(32, block_id=1, stride=2))\n",
    "\n",
    "        self.cur_input_size = int(self.cur_input_size/2)\n",
    "        self.layers.extend(self._make_layer(64, block_id=2, stride=2))\n",
    "\n",
    "        end_layers = []\n",
    "\n",
    "        end_layers.append(nn.AvgPool2d(kernel_size=8))\n",
    "        end_layers.append(af.Flatten())\n",
    "        end_layers.append(nn.Linear(64*self.block.expansion, self.num_classes))\n",
    "        self.end_layers = nn.Sequential(*end_layers)\n",
    "\n",
    "        if self.init_weights:\n",
    "            self.initialize_weights()\n",
    "\n",
    "    def _make_layer(self, channels, block_id, stride):\n",
    "        num_blocks = int(self.num_blocks[block_id])\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for cur_block_id, stride in enumerate(strides):\n",
    "            add_output = self.add_out_nonflat[block_id][cur_block_id]\n",
    "            params  = (add_output, self.num_classes, int(self.cur_input_size), self.cur_output_id)\n",
    "            layers.append(self.block(self.in_channels, channels, params, stride))\n",
    "            self.in_channels = channels * self.block.expansion\n",
    "            self.cur_output_id += add_output\n",
    "\n",
    "        return layers\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def random_rp_matrix(self):\n",
    "        param = next(self.init_conv[0].parameters())\n",
    "        kernel_size = param.data.size()[-1]\n",
    "        param.data = torch.normal(mean=0.0, std=1/kernel_size, size=param.data.size()).to('cuda')\n",
    "\n",
    "    def rp_forward(self, x, out, kernel):\n",
    "        rp_out = kernel(x)\n",
    "        if out is None:\n",
    "            return rp_out\n",
    "        else:\n",
    "            out = torch.cat([out, rp_out], dim=1)\n",
    "            return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        if self.use_rpf:\n",
    "            fwd = self.init_conv[0](x)\n",
    "            fwd = self.rp_forward(x, fwd, self.init_conv[1])\n",
    "            fwd = self.init_conv[2](fwd)\n",
    "        else:\n",
    "            fwd = self.init_conv(x)\n",
    "        for layer in self.layers:\n",
    "            fwd, is_output, output = layer(fwd)\n",
    "            if is_output:\n",
    "                if len(outputs) == self.stop_ic_id:\n",
    "                    return output\n",
    "                outputs.append(output)\n",
    "        fwd = self.end_layers(fwd)\n",
    "        outputs.append(fwd)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    # takes a single input\n",
    "    def early_exit(self, x):\n",
    "        device = next(self.parameters()).device\n",
    "        confidences = []\n",
    "        outputs = []\n",
    "        batch_size = x.shape[0]\n",
    "        result = torch.zeros(batch_size, dtype=torch.long).to(device)\n",
    "        stop_at = torch.zeros(batch_size).to(device)\n",
    "        stopped = torch.tensor([0]*batch_size, dtype=torch.bool).to(device)\n",
    "        if self.use_rpf:\n",
    "            fwd = self.init_conv[0](x)\n",
    "            fwd = self.rp_forward(x, fwd, self.init_conv[1])\n",
    "            fwd = self.init_conv[2](fwd)\n",
    "        else:\n",
    "            fwd = self.init_conv(x)\n",
    "        output_id = 0\n",
    "        for layer in self.layers:\n",
    "            fwd, is_output, output = layer(fwd)\n",
    "\n",
    "            if is_output:\n",
    "                softmax = nn.functional.softmax(output, dim=1)\n",
    "                softmax[stopped] = 0\n",
    "                confidence = torch.max(softmax, dim=1)\n",
    "                stop_index = (confidence.values > self.confidence_threshold).view(-1)\n",
    "                result[stop_index] = confidence.indices[stop_index]\n",
    "                stop_at[stop_index] = output_id\n",
    "                stopped[stop_index] = True\n",
    "                output_id += is_output\n",
    "\n",
    "        output = self.end_layers(fwd)\n",
    "        softmax = nn.functional.softmax(output, dim=1)\n",
    "        confidence = torch.max(softmax, dim=1)\n",
    "        result[~stopped] = confidence.indices[~stopped]\n",
    "        stop_at[stop_index] = -1\n",
    "        return result, stop_at\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5164ff82-2e34-4136-8d07-d2a830636478",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {}\n",
    "model_params['task'] = 'cifar10'\n",
    "model_params['input_size'] = 32\n",
    "model_params['num_classes'] = 10\n",
    "model_params['block_type'] = 'basic'\n",
    "model_params['num_blocks'] = [9,9,9]\n",
    "model_params['add_ic'] = [[0, 0, 0, 1, 0, 0, 0, 1, 0], [0, 0, 1, 0, 0, 0, 1, 0, 0], [0, 1, 0, 0, 0, 1, 0, 0, 0]] # 15, 30, 45, 60, 75, 90 percent of GFLOPs\n",
    "model_params['network_type'] = 'resnet56'\n",
    "model_params['augment_training'] = True\n",
    "model_params['init_weights'] = True\n",
    "model_params['architecture'] = 'sdn'\n",
    "model_params['base_model'] = 'resnet56'\n",
    "network_type = model_params['network_type']\n",
    "model_params['momentum'] = 0.9\n",
    "model_params['learning_rate'] = 0.1\n",
    "model_params['epochs'] = 100\n",
    "model_params['milestones'] = [35, 60, 85]\n",
    "model_params['gammas'] = [0.1, 0.1, 0.1]\n",
    "                          \n",
    "model_params['init_rpf_pannel'] = 8\n",
    "model_params['use_rpf'] = True\n",
    "\n",
    "# SDN ic_only training params\n",
    "model_params['ic_only'] = {}\n",
    "model_params['ic_only']['learning_rate'] = 0.001 # lr for full network training after sdn modification\n",
    "model_params['ic_only']['epochs'] = 25\n",
    "model_params['ic_only']['milestones'] = [15]\n",
    "model_params['ic_only']['gammas'] = [0.1]\n",
    "model = ResNet_SDN(model_params).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3a18135a-fabe-44b3-9908-efea2fc457e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.random_rp_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5c3f5559-eb3d-4a84-9905-577749b8a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_shape = [128,3, 32, 32]\n",
    "test_input = torch.rand(batch_shape).cuda()\n",
    "model.confidence_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2267f185-2b1c-4a5e-8770-7e21d101c43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 5, 2, 1, 5, 2, 2, 2, 4, 2, 7, 7, 5, 2, 2, 6, 2, 2, 2, 2, 2, 2, 2, 5,\n",
       "         7, 2, 5, 5, 6, 2, 4, 2, 2, 2, 2, 2, 2, 2, 7, 2, 2, 2, 2, 2, 2, 7, 2, 2,\n",
       "         2, 6, 2, 5, 5, 6, 5, 6, 2, 6, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5,\n",
       "         2, 2, 2, 7, 6, 5, 6, 2, 7, 7, 2, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 2, 5, 2,\n",
       "         7, 5, 7, 7, 2, 2, 2, 2, 2, 6, 2, 2, 6, 2, 6, 2, 6, 2, 5, 2, 5, 6, 2, 2,\n",
       "         2, 5, 5, 6, 2, 2, 4, 7], device='cuda:0'),\n",
       " tensor([0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 2., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 2., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 2., 0., 1., 1., 2.,\n",
       "         1., 2., 0., 2., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "         0., 0., 0., 1., 2., 1., 2., 0., 1., 1., 0., 0., 0., 2., 0., 0., 2., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 2., 0., 0.,\n",
       "         2., 0., 2., 0., 2., 0., 1., 0., 1., 2., 0., 0., 0., 1., 1., 2., 0., 0.,\n",
       "         0., 1.], device='cuda:0'))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.early_exit(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8925b8c8-65d4-4b25-86ac-f764bb7b11ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a3a429bc-7573-4dd5-9a43-97aace6021fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.8099e-01, 3.5474e-01, 6.1766e-01, 1.2564e-01, 7.5395e-01],\n",
       "        [3.3816e-01, 9.5851e-01, 5.5834e-01, 8.6521e-01, 3.3673e-01],\n",
       "        [6.6410e-01, 1.6172e-01, 9.6324e-01, 8.6379e-01, 1.0377e-01],\n",
       "        [8.6072e-01, 4.3179e-01, 8.1198e-01, 1.4278e-01, 5.9718e-01],\n",
       "        [8.1437e-01, 6.6839e-01, 6.2485e-01, 2.5642e-01, 1.3471e-04]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(5,5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d16040d2-da35-47b5-9cd3-87b367712559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1905, 0.1809, 0.1772, 0.1641, 0.2873],\n",
       "        [0.1998, 0.1985, 0.2024, 0.1979, 0.2013],\n",
       "        [0.1666, 0.2718, 0.1974, 0.2413, 0.1229],\n",
       "        [0.2608, 0.1853, 0.2334, 0.1453, 0.1753],\n",
       "        [0.2495, 0.2011, 0.2071, 0.2440, 0.0982]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = F.softmax(a, dim=1)\n",
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7326c209-6c0c-4a5f-9d05-5794b508340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = torch.max(softmax, dim=1)\n",
    "stop_index = (confidence.values > 0.25).view(-1)\n",
    "result = torch.zeros(5)\n",
    "stop_layer = torch.zeros(5)\n",
    "stopped = torch.tensor([0]*5, dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d87177e8-3f00-42cd-af3f-4ed15f832e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[stop_index] = confidence.indices[stop_index].float()\n",
    "stop_layer[stop_index] = 1\n",
    "stopped[stop_index] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "69d75882-fec0-4cf3-b7c8-a017797f71b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax[stopped] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2d78b646-345c-4d69-a200-4791f5eae034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1998, 0.1985, 0.2024, 0.1979, 0.2013],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2495, 0.2011, 0.2071, 0.2440, 0.0982]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "170b4d29-e041-4c05-9529-8757f53e2a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 2, 1, 0, 0])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e41331-7c09-45d0-bfce-5534690bc333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
